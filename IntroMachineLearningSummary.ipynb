{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f6ccd2-0c8c-4d41-b19f-e5bd8036f66e",
   "metadata": {},
   "source": [
    "This is an introduction to machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f21a3-d46f-4285-af91-53f408d21265",
   "metadata": {},
   "source": [
    "The scenario used:\n",
    "Your cousin has made millions of dollars speculating on real estate. He's offered to become business partners with you because of your interest in data science. He'll supply the money, and you'll supply models that predict how much various houses are worth."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f53c0495-fd27-4021-b867-df072a16cc61",
   "metadata": {},
   "source": [
    "A basic model: decision tree\n",
    "A decision tree is a decision support hierarchical model that uses a tree-like model of decisions and their possible consequences.\n",
    "\n",
    "We use data to decide how to break the houses into two groups, and then again to determine the predicted price in each group. This step of capturing patterns from data is called fitting or training the model. The data used to fit the model is called the training data.\r\n",
    "\r\n",
    "The details of how the model is fit (e.g. how to split up the data) is complex enough that we will save it for later. After the model has been fit, you can apply it to new data to predict prices of additional home\n",
    "\n",
    "The predicted price for the house is at the bottom of the tree. The point at the bottom where we make a prediction is called a leaf.\n",
    "\n",
    "visual representation of a decision tree: https://storage.googleapis.com/kaggle-media/learn/images/prAjgku.pngs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b467cbf-a2c7-45a5-9d7c-aeed83ca4d89",
   "metadata": {},
   "source": [
    "1. Preparation for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74747fd-c79e-4098-aceb-8c3f68cd3a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5353902d-8990-47ca-ba58-8d9edd837728",
   "metadata": {},
   "source": [
    "The most important part of the Pandas library is the DataFrame. A DataFrame holds the type of data you might think of as a table. This is similar to a sheet in Excel, or a table in a SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4812b5f4-7c34-496a-9751-b644dec8f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data initialisation\n",
    "# save filepath to variable for easier access\n",
    "# the content in the '' is the location of the data file, which can be varied on different devices\n",
    "melbourne_file_path ='Desktop/MELBOURNE_HOUSE_PRICES_LESS.csv'\n",
    "# read the data and store data in DataFrame titled melbourne_data\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200bf483-fb87-4918-9538-dfe7aaae64f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Rooms         Price      Postcode  Propertycount      Distance\n",
      "count  63023.000000  4.843300e+04  63023.000000   63023.000000  63023.000000\n",
      "mean       3.110595  9.978982e+05   3125.673897    7617.728131     12.684829\n",
      "std        0.957551  5.934989e+05    125.626877    4424.423167      7.592015\n",
      "min        1.000000  8.500000e+04   3000.000000      39.000000      0.000000\n",
      "25%        3.000000  6.200000e+05   3056.000000    4380.000000      7.000000\n",
      "50%        3.000000  8.300000e+05   3107.000000    6795.000000     11.400000\n",
      "75%        4.000000  1.220000e+06   3163.000000   10412.000000     16.700000\n",
      "max       31.000000  1.120000e+07   3980.000000   21650.000000     64.100000\n",
      "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
      "       'Date', 'Postcode', 'Regionname', 'Propertycount', 'Distance',\n",
      "       'CouncilArea'],\n",
      "      dtype='object')\n",
      "         Suburb           Address  Rooms Type      Price Method   SellerG  \\\n",
      "0    Abbotsford     49 Lithgow St      3    h  1490000.0      S    Jellis   \n",
      "1    Abbotsford     59A Turner St      3    h  1220000.0      S  Marshall   \n",
      "2    Abbotsford     119B Yarra St      3    h  1420000.0      S    Nelson   \n",
      "3    Aberfeldie        68 Vida St      3    h  1515000.0      S     Barry   \n",
      "4  Airport West  92 Clydesdale Rd      2    h   670000.0      S    Nelson   \n",
      "\n",
      "        Date  Postcode             Regionname  Propertycount  Distance  \\\n",
      "0  1/04/2017      3067  Northern Metropolitan           4019       3.0   \n",
      "1  1/04/2017      3067  Northern Metropolitan           4019       3.0   \n",
      "2  1/04/2017      3067  Northern Metropolitan           4019       3.0   \n",
      "3  1/04/2017      3040   Western Metropolitan           1543       7.5   \n",
      "4  1/04/2017      3042   Western Metropolitan           3464      10.4   \n",
      "\n",
      "                  CouncilArea  \n",
      "0          Yarra City Council  \n",
      "1          Yarra City Council  \n",
      "2          Yarra City Council  \n",
      "3  Moonee Valley City Council  \n",
      "4  Moonee Valley City Council  \n"
     ]
    }
   ],
   "source": [
    "# data representation\n",
    "# print a summary of the data in Melbourne data\n",
    "print(melbourne_data.describe())\n",
    "# print a list of columns contained in the data file\n",
    "print(melbourne_data.columns)\n",
    "# print a small part of the table in the data file\n",
    "print(melbourne_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74bde6e2-9cba-40fc-bca2-38e2858d66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refining the data file\n",
    "# The Melbourne data has some missing values (some houses for which some variables weren't recorded.)\n",
    "# dropna drops missing values (think of na as \"not available\")\n",
    "melbourne_data = melbourne_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32babcd7-b8f2-4f53-949d-809fca65d055",
   "metadata": {},
   "source": [
    "2. Select data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8492e087-2383-492c-b538-8c6f8e75d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a prediction target fromt the columns of the data file\n",
    "# conventionally, y is used as an variable to represent the prediction target \n",
    "y = melbourne_data.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3cff14-63da-4f35-95fb-1a8f1244b2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rooms  Postcode  Distance\n",
      "0      3      3067       3.0\n",
      "1      3      3067       3.0\n",
      "2      3      3067       3.0\n",
      "3      3      3040       7.5\n",
      "4      2      3042      10.4\n",
      "              Rooms      Postcode      Distance\n",
      "count  48433.000000  48433.000000  48433.000000\n",
      "mean       3.071666   3123.210332     12.702761\n",
      "std        0.944708    125.534940      7.550030\n",
      "min        1.000000   3000.000000      0.000000\n",
      "25%        2.000000   3051.000000      7.000000\n",
      "50%        3.000000   3103.000000     11.700000\n",
      "75%        4.000000   3163.000000     16.700000\n",
      "max       31.000000   3980.000000     55.800000\n"
     ]
    }
   ],
   "source": [
    "# choose features from the columns of the data file\n",
    "# The columns that are inputted into our model (and later used to make predictions) are called \"features.\" \n",
    "# In our case, those would be the columns used to determine the home price.\n",
    "melbourne_features = [ 'Rooms','Postcode','Distance']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "# visualize the features, X\n",
    "print(X.head())\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee18c47-69ea-4c8d-ad1b-f18904e59042",
   "metadata": {},
   "source": [
    "3. Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187e2779-9f7d-41b5-826d-a078f2abaa83",
   "metadata": {},
   "source": [
    "The steps to building and using a model are:\r\n",
    "    \r\n",
    "Define: What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified t \n",
    " .\r\n",
    "Fit: Capture patterns from provided data. This is the heart of mode  \n",
    " g.\r\n",
    "Predict: Just what it soun   .\n",
    " ike\r\n",
    "Evaluate: Determine how accurate the model's predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f35d48a0-458e-496c-8337-b5b785409235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit model\n",
    "melbourne_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c3f4ec4-7c04-41a6-b5d1-aa8fbe7d572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for the following 5 houses:\n",
      "   Rooms  Postcode  Distance\n",
      "0      3      3067       3.0\n",
      "1      3      3067       3.0\n",
      "2      3      3067       3.0\n",
      "3      3      3040       7.5\n",
      "4      2      3042      10.4\n",
      "The predictions are\n",
      "[1241833.33333333 1241833.33333333 1241833.33333333 1162721.97309417\n",
      "  647622.09302326]\n"
     ]
    }
   ],
   "source": [
    "# making predictions and visualizing them\n",
    "print(\"Making predictions for the following 5 houses:\")\n",
    "print(X.head())\n",
    "print(\"The predictions are\")\n",
    "print(melbourne_model.predict(X.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b378e-b83a-4505-b821-3479848cb046",
   "metadata": {},
   "source": [
    "4. Model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629abd4-d095-4a9c-a652-3007adeac94c",
   "metadata": {},
   "source": [
    "To conduct a model validation check, you'd first need to summarize the model quality into an understandable way. If you compare predicted and actual home values for 10,000 houses, you'll likely find mix of good and bad predictions. Looking through a list of 10,000 predicted and actual values would be pointless. We need to summarize this into a single metric.\r\n",
    "\r\n",
    "There are many metrics for summarizing model quality, but we'll start with one called Mean Absolute Error (also called MAE\n",
    "\n",
    "MAE = the average of the absolute values of the difference between the predicted values and the actual valuesr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b62f09a-1744-44de-be82-1eb19b02b454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202264.1656746377"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ff628-f7b8-4b35-9960-221f5eecda21",
   "metadata": {},
   "source": [
    "Since models' practical value come from making predictions on new data, it's better to measure performance on data that wasn't used to build the model.\n",
    "\n",
    "The most straightforward way to do this is to exclude some data from the model-building process, and then use those to test the model's accuracy on data it hasn't seen before. This data is called validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1eac7d1-b112-42e4-b944-be52ea484564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209132.22922836881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time \n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, train_size=0.8,test_size=0.2, random_state = 0)\n",
    "# Define model\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "# Fit model\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "# get predicted prices on validation data\n",
    "val_predictions = melbourne_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f72f7ea-be49-46bc-b076-c37cd82707f8",
   "metadata": {},
   "source": [
    "5. Problems: underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd923c52-0214-4d05-8e8c-5c394220d11c",
   "metadata": {},
   "source": [
    "In a decision tree model, the depth of the tree influences the accuracy of the result of the model.\n",
    "\n",
    "As the tree gets deeper, the dataset gets sliced up into leaves with fewer houses. If a tree only had 1 split, it divides the data into 2 groups. If each group is split again, we would get 4 groups of houses. Splitting each of those again would create 8 groups. If we keep doubling the number of groups by adding more splits at each level, we'll have 2^10=1024 groups of houses by the time we get to the 10th level. \n",
    "\n",
    "Overfitting: when we divide the houses amongst many leaves, we also have fewer houses in each leaf. Leaves with very few houses will make predictions that are quite close to those homes' actual values, but they may make very unreliable predictions for new data (because each prediction is based on only a few houses).\r\n",
    "Underfitting: when the decision tree has fewer splits, the prediction might be inaccurate even for the training data as some important features/patterns are not captured.\n",
    "\n",
    "https://storage.googleapis.com/kaggle-media/learn/images/AXSEOfI.pngng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbc894c8-2ad3-4688-99b2-70b020b9a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  342446\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  229001\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  209375\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  209115\n"
     ]
    }
   ],
   "source": [
    "# find the most accurate model by comparing the max number of leaf nodes \n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)\n",
    "\n",
    "# compare MAE with differing values of max_leaf_nodes, for example:5,50,500,5000 leaves\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca0d3bd-5d25-4864-9543-9977dfd07210",
   "metadata": {},
   "source": [
    "Overfitting: capturing spurious patterns that won't recur in the future, leading to less accurate predictions, or\n",
    "Underfitting: failing to capture relevant patterns, again leading to less accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6ae9f-91c9-41e1-8f82-f92eecf50689",
   "metadata": {},
   "source": [
    "6. Another model: random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6928e7b0-73b5-495e-862e-15db05e9dbff",
   "metadata": {},
   "source": [
    "Even today's most sophisticated modeling techniques face this tension between underfitting and overfitting. But, many models have clever ideas that can lead to better performance. For instance, random forest.\n",
    "\n",
    "The random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and it works well with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "458a780a-7fa9-416f-bb52-aeb8ce8129c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208530.33606399526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
